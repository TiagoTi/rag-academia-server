# Sistema RAG para Base de Dados Acad√™mica

Este reposit√≥rio cont√©m o **RAG Server**, um componente essencial do ecossistema de assist√™ncia acad√™mica. O sistema utiliza a t√©cnica de RAG (*Retrieval-Augmented Generation*) para permitir a busca e recupera√ß√£o sem√¢ntica de documentos acad√™micos atrav√©s de embeddings vetoriais, fornecendo contexto relevante para modelos de linguagem (LLMs).

## üåê Ecossistema

Este projeto faz parte de um ecossistema integrado composto por tr√™s reposit√≥rios principais:

1.  **RAG Server (Este reposit√≥rio):** Gerencia a base de dados vetorial, processa documentos Markdown e fornece uma API para busca sem√¢ntica.
    -   [GitHub](https://github.com/TiagoTi/rag-academia-server)
2.  **MCP Server (Model Context Protocol):** Fornece ferramentas espec√≠ficas para consulta de exerc√≠cios f√≠sicos e grupos musculares via protocolo MCP.
    -   [GitHub](https://github.com/TiagoTi/mcp-academia-server)
3.  **Chatbot API Server:** Atua como o orquestrador central, integrando as respostas do RAG e do MCP com o Ollama para gerar respostas finais ao usu√°rio.
    -   [GitHub](https://github.com/TiagoTi/chat-academia-server)

### Arquitetura do Sistema

```mermaid
graph TD
    User((Usu√°rio)) --> Chatbot[Chatbot API Server :3403]
    Chatbot --> RAG[RAG Server :3402]
    Chatbot --> MCP[MCP Server :3401]
    RAG --> Ollama[Ollama :11434]
    Chatbot --> Ollama
    Ollama --> Embed[nomic-embed-text]
    Ollama --> LLM[mistral]
```

---

## üöÄ Funcionalidades

-   **Busca Vetorial**: Realiza busca sem√¢ntica utilizando similaridade de cosseno em embeddings de documentos.
-   **Ingest√£o de Documentos**: Processamento autom√°tico, fragmenta√ß√£o (*chunking*) e limpeza de documentos em formato Markdown.
-   **API REST**: Endpoint HTTP para consulta de documentos similares.
-   **Banco de Dados SQLite**: Armazenamento eficiente e local para documentos e seus respectivos vetores.
-   **Integra√ß√£o com Ollama**: Utiliza√ß√£o de modelos como `nomic-embed-text` para gera√ß√£o de representa√ß√µes vetoriais.
-   **Dockerizado**: Pronto para deploy em containers com persist√™ncia de dados.
-   **TypeScript & Bun**: Desenvolvido com TypeScript e otimizado para o ambiente de execu√ß√£o Bun.

---

## üõ†Ô∏è Pr√©-requisitos

Antes de iniciar, certifique-se de ter instalado:

1.  **Bun**: Runtime JavaScript/TypeScript ([Instala√ß√£o](https://bun.sh/))
2.  **Ollama**: Para execu√ß√£o local de modelos de IA ([Instala√ß√£o](https://ollama.ai/))
    -   Execute: `ollama pull nomic-embed-text:latest`
3.  **Docker** (Opcional, para execu√ß√£o em container)

---

## üì¶ Instala√ß√£o e Configura√ß√£o

### 1. Clonar e Instalar

```bash
git clone https://github.com/TiagoTi/rag-academia-server.git
cd rag-academia-server
bun install
```

### 2. Prepara√ß√£o de Documentos

Para alimentar o sistema com conhecimento:

1.  Coloque seus arquivos `.md` na pasta `arquivos/novos/`.
2.  Gere os embeddings executando:
    ```bash
    bun run insert-embeddings.ts
    ```

**O que este script faz:**
- L√™ os arquivos em `arquivos/novos/`.
- Fragmenta o conte√∫do em partes menores.
- Gera os vetores (embeddings) via Ollama.
- Salva tudo no arquivo `embeddings.sqlite`.
- Move os documentos originais para `arquivos/processados/`.

---

## üîå Executando o Servidor

### Localmente

Inicie o servidor de API:

```bash
bun run api.ts
```

O servidor estar√° dispon√≠vel em `http://localhost:3000` (ou na porta definida pela vari√°vel `PORT`).

### Via Docker

#### Constru√ß√£o da Imagem:
```bash
docker build --pull -t rag-server-academia .
```

#### Execu√ß√£o do Container:
```bash
docker run \
  --restart=always \
  --name rag-server-academia \
  --network host \
  -d \
  -v $(pwd)/embeddings.sqlite:/tmp/embeddings.sqlite \
  -e OLLAMA_BASE_URL=http://localhost:11434 \
  -e DB_PATH=/tmp/embeddings.sqlite \
  rag-server-academia
```

---

## üìÑ Refer√™ncia da API

### `POST /api/embeddings`

Busca os trechos de documentos mais relevantes para um determinado texto.

**Exemplo de corpo da requisi√ß√£o:**

```json
{
  "prompt": "Quais s√£o as orienta√ß√µes para treino de hipertrofia?",
  "topK": 3,
  "limiarSimilaridade": 0.5
}
```

**Exemplo com cURL:**

```bash
curl -X POST http://localhost:3000/api/embeddings \
  -H "Content-Type: application/json" \
  -d '{"prompt": "hipertrofia", "topK": 2}'
```

---

## ‚öôÔ∏è Vari√°veis de Ambiente

| Vari√°vel | Descri√ß√£o | Padr√£o |
|----------|-----------|---------|
| `PORT` | Porta do servidor API | `3000` |
| `DB_PATH` | Caminho do banco SQLite | `./embeddings.sqlite` |
| `OLLAMA_BASE_URL` | URL da API do Ollama | `http://localhost:11434` |

---

## üîç Solu√ß√£o de Problemas

-   **ECONNREFUSED 127.0.0.1:11434**: O Ollama n√£o est√° rodando ou n√£o est√° acess√≠vel. Se estiver no Docker, utilize `host.docker.internal` ou o IP da rede host.
-   **Model not found**: Certifique-se de que executou `ollama pull nomic-embed-text`.
-   **Database locked**: Verifique se n√£o h√° m√∫ltiplos processos tentando acessar o arquivo `embeddings.sqlite` simultaneamente.

---

## üìù Licen√ßa

Este projeto √© licenciado sob a licen√ßa MIT.
